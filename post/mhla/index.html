<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: January 24, 2025 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.9.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.7eaca94f0cfe2f9115699dbdb8fbc775.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



























  
  
  






  <meta name="author" content="Zhengxiao Du" />





  

<meta name="description" content="关于 MHLA的一些分析" />



<link rel="alternate" hreflang="en-us" href="https://zxdu.xyz/post/mhla/" />
<link rel="canonical" href="https://zxdu.xyz/post/mhla/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu201e1a72013825f24e615b24fa4a82e9_325334_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu201e1a72013825f24e615b24fa4a82e9_325334_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="https://zxdu.xyz/media/icon_hu201e1a72013825f24e615b24fa4a82e9_325334_512x512_fill_lanczos_center_3.png" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="Zhengxiao Du" />
<meta property="og:url" content="https://zxdu.xyz/post/mhla/" />
<meta property="og:title" content="关于 MHLA（Multi-Head Latent Attention）的一些分析 | Zhengxiao Du" />
<meta property="og:description" content="关于 MHLA的一些分析" /><meta property="og:image" content="https://zxdu.xyz/media/icon_hu201e1a72013825f24e615b24fa4a82e9_325334_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2024-05-09T21:26:09&#43;08:00"
    />
  
  
    <meta property="article:modified_time" content="2024-05-10T17:55:09&#43;08:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://zxdu.xyz/post/mhla/"
  },
  "headline": "关于 MHLA（Multi-Head Latent Attention）的一些分析",
  
  "datePublished": "2024-05-09T21:26:09+08:00",
  "dateModified": "2024-05-10T17:55:09+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Zhengxiao Du"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Zhengxiao Du",
    "logo": {
      "@type": "ImageObject",
      "url": "https://zxdu.xyz/media/icon_hu201e1a72013825f24e615b24fa4a82e9_325334_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "关于 MHLA的一些分析"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>关于 MHLA（Multi-Head Latent Attention）的一些分析 | Zhengxiao Du</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll"  data-target="#TableOfContents" class="page-wrapper   no-navbar" data-wc-page-id="52df302f05bd06530a527cd80f3aa7b1" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.e6724bea461adf2acc4820665a329eca.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  


  </div>

  <div class="page-body">
    
    
    
      
      
      <div class="article-container py-1" style="background: initial">
        
  <nav class="d-none d-md-flex" aria-label="breadcrumb">
    <ol class="breadcrumb">
      
  
    
  
    
  

    <li class="breadcrumb-item">
      <a href="/">
        
          Home
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/post/">
        
          Posts
        
      </a>
    </li>
  

      <li class="breadcrumb-item active" aria-current="page">
        关于 MHLA（Multi-Head Latent Attention）的一些分析
      </li>
    </ol>
  </nav>




      </div>
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>关于 MHLA（Multi-Head Latent Attention）的一些分析</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/zhengxiao-du/">Zhengxiao Du</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    May 10, 2024
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/%E6%8A%80%E6%9C%AF/">技术</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>原始的 Multi-Head Attention 的计算公式为（单个head，暂时先不考虑 RoPE）</p>
<p>$$
Q_i=W^Q_iH
$$</p>
<p>$$
K_i=W_i^KH
$$
$$
V_i=W^V_iH
$$
$$
O_i=\text{Softmax}(\frac{Q_i^TK_i}{\sqrt{d_h}})V_i
$$
其中$H$ 是 $d\times l$ 的矩阵（$l$ 为序列长度），表示 hidden states， $W^Q_i, W^K_i, W^V_i$ 是 $d_h\times d$的矩阵。</p>
<p>Multi-Query Attention 的计算公式为（单个head，暂时先不考虑 RoPE）
$$
Q_i=W^Q_iH
$$</p>
<p>$$
K=W^KH
$$
$$
V=W^VH
$$
$$
O_i=Softmax(\frac{Q_i^TK}{\sqrt{d_h}})V_i
$$
最大的区别在于 $K,V$ 是所有 head共享的，因此能够减少KV Cache的显存占用。其中
$$
Q_i^TK=H^T(W_i^Q)^TW^KH
$$
Multi-Head Latent Attention 的计算公式为（单个head，暂时先不考虑 RoPE）
$$
C^Q=W^{DQ}H
$$
$$
Q_i=W^{UQ}_iC^Q
$$
$$
C^{KV}=W^{DKV}H
$$
$$
K_i=W_i^{UK}C^{KV}
$$
$$
V_i=W_i^{UV}C^{KV}
$$
$$
O_i=Softmax(\frac{Q_i^TK_i}{\sqrt{d_h}})V_i
$$
其中 $W^{DQ}, W^{DKV}\in \mathbb{R}^{d_c\times d}$，$W_i^{UQ},W_i^{UK},W_i^{UV}\in\mathbb{R}^{d_h\times d_c}$</p>
<p>单独看 Attention 计算的前一部分，其中
$$
Q_i^TK_i=H^T(W^{DQ})^T(W_i^{UQ})^TW^{UK}_iW^{DKV}H
$$
令 $W_i^Q=(W_i^{UK})^TW_i^{UQ}W^{DQ}$，我们有
$$
Q_i^TK_i=H^T(W_i^Q)^TW^{DKV}H
$$
可以看到这一计算公式和 Multi-Query Attention 其实是一样的，都是使用的单独的 $Q$ 和共享的 $K$。区别在于，这里 $W_i^QH,W^{DKV}H\in\mathbb{R}^{d_c\times l}$。也就是说在进行 attention 计算的时候，向量点积的维度是 $d_c$  而不是 $d$。在论文中实际设置的是 $d_c=4d$。<strong>也就是说 Multi-Head Latent Attention 其实是 head dimension 提高到4倍的 Multi-Query Attention</strong>。在论文中也提到了在 inference 的时候 absorb $W^{UK}$ into $W^{UQ}$，其实就代表了这里的结合方式。因为每个head的维度提高了，所以能够计算出更加复杂的 attention分布，从而相比起 Multi-Query Attention 取得性能提升。相比起直接提高 head dimension，其优点在于所有head的 $W^{DQ},W^{UQ},W^{UK}$的总参数量是 $d\cdot d_c+d \cdot d_c+ d \cdot d_c=3d\cdot d_c=12d\cdot d_h$，而所有 head 的 $W^Q$ 的参数量是 $d \cdot d_c\cdot n_h=4d^2$，节省了参数量。也就是说对 $W^Q$ 做了一个低秩分解。</p>
<p>但是这个提升并不是 free lunch，因为 head dimension 提高意味着 attention 的计算量也提高，而 attention 的计算量是 $O(l^2)$ 的。为了处理长文本，现在大家一般都倾向于尽可能降低 attention 计算量的常数，而这个方法是会增加常数的。</p>
<p>以上分析没有考虑 RoPE，如果考虑 RoPE 的话，每个 head 的维度会从 $4d$ 变成 $4.5d$，其中$4d$是没有 positional encoding的，$0.5d$ 是使用 RoPE encoding的。其实 ChatGLM2-6B 中已经使用过类似的<a href="https://huggingface.co/THUDM/chatglm2-6b/blob/main/modeling_chatglm.py#L161" target="_blank" rel="noopener">做法</a>，即只在一半的 head dimension 上使用 RoPE ，目的是为了把 attention 计算分成位置相关和位置无关的两部分，与性能提升的关系并不大。</p>

    </div>

    







<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fzxdu.xyz%2Fpost%2Fmhla%2F&amp;text=%E5%85%B3%E4%BA%8E&#43;MHLA%EF%BC%88Multi-Head&#43;Latent&#43;Attention%EF%BC%89%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fzxdu.xyz%2Fpost%2Fmhla%2F&amp;t=%E5%85%B3%E4%BA%8E&#43;MHLA%EF%BC%88Multi-Head&#43;Latent&#43;Attention%EF%BC%89%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook-f">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=%E5%85%B3%E4%BA%8E%20MHLA%EF%BC%88Multi-Head%20Latent%20Attention%EF%BC%89%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90&amp;body=https%3A%2F%2Fzxdu.xyz%2Fpost%2Fmhla%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fzxdu.xyz%2Fpost%2Fmhla%2F&amp;title=%E5%85%B3%E4%BA%8E&#43;MHLA%EF%BC%88Multi-Head&#43;Latent&#43;Attention%EF%BC%89%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=%E5%85%B3%E4%BA%8E&#43;MHLA%EF%BC%88Multi-Head&#43;Latent&#43;Attention%EF%BC%89%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90%20https%3A%2F%2Fzxdu.xyz%2Fpost%2Fmhla%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fzxdu.xyz%2Fpost%2Fmhla%2F&amp;title=%E5%85%B3%E4%BA%8E&#43;MHLA%EF%BC%88Multi-Head&#43;Latent&#43;Attention%EF%BC%89%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    




  







  
  
  

  

  
  <section id="comments">
    <div id="twikoo"></div>
<script src="https://cdn.staticfile.org/twikoo/1.6.32/twikoo.all.min.js"></script>
<script>
twikoo.init({
  envId: 'https://twikoo.zxdu.xyz', 
  el: '#twikoo', 
  
  
  
})
</script>
  </section>
  




<div class="article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/post/vector-quantize/" rel="next">从零学习 Vector Quantization</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/post/bitwarden/" rel="prev">用Vaultwarden搭建自己的密码管理服务</a>
  </div>
  
</div>

</div>




  
  




  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2025 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.5434e222df551c9e1b69d4b459b17aeb.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
