<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 | Zhengxiao Du</title>
    <link>https://zxdu.xyz/category/%E6%8A%80%E6%9C%AF/</link>
      <atom:link href="https://zxdu.xyz/category/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <description>技术</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Sep 2024 00:00:00 +0800</lastBuildDate>
    <image>
      <url>https://zxdu.xyz/media/icon_hu201e1a72013825f24e615b24fa4a82e9_325334_512x512_fill_lanczos_center_3.png</url>
      <title>技术</title>
      <link>https://zxdu.xyz/category/%E6%8A%80%E6%9C%AF/</link>
    </image>
    
    <item>
      <title>从零学习 Vector Quantization</title>
      <link>https://zxdu.xyz/post/vector-quantize/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0800</pubDate>
      <guid>https://zxdu.xyz/post/vector-quantize/</guid>
      <description>&lt;p&gt;最近因为研究需要学习了 vector quantization（VQ）并且实际训练了一些带有 VQ bottleneck 的模型。在这里记录一下学习和训练的心得。&lt;/p&gt;
&lt;h2 id=&#34;什么是-vq&#34;&gt;什么是 VQ&lt;/h2&gt;
&lt;p&gt;我们知道神经网络强大的表示能力很大程度上来自于其使用的连续向量表示，以及依赖于连续向量表示的梯度下降优化算法。而 vector quantization 则是将神经网络中某一层的连续向量表示替换为离散变量。具体方式为有一个词表（codebook） $e\in R^{K\times D}$，其中$K$ 是词表大小，$D$ 是向量维度。对于神经网络中某一层的输出 $z\in R^{D}$，我们希望找到一个词表中的向量 $e_i$ 使得 $e_i$ 与 $z$ 的距离最小，即 $i = \arg\min_j |x - e_j|_2$。这样，我们就可以将 $e_i$ 作为 $z$ 的近似，称为 $z_q$，继续参与后面的运算。这种替换方式可以看作是一种量化（quantization）操作，因此得名 vector quantization。&lt;/p&gt;
&lt;h2 id=&#34;为什么需要-vq&#34;&gt;为什么需要 VQ&lt;/h2&gt;
&lt;p&gt;VQ 最为知名的应用就是 VQVAE，常常被用于将原始图片编码为离散的 token 序列。但是实际上 VQ 可以用于任何神经网络中，并不局限于 AutoEncoder。&lt;/p&gt;
&lt;p&gt;VQ 可以看作是 Transformer 中 embedding 层的逆运算。Embedding 层的作用就是将神经网络不好处理的离散变量转化为连续向量表示，为什么我们还需要反过来呢？离散变量的优点在于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;更适合作为生成任务的目标。我们已经知道自回归 Transformer 能够很好地建模自然语言这样的离散序列。而连续向量序列，比如原始的图片、音频等，往往需要 diffusion model 这样更复杂的生成模型来建模。&lt;/li&gt;
&lt;li&gt;节省存储空间。连续变量 $z$ 需要存储 $D$ 个浮点数，而离散变量 $e_i$ 只需要存储一个整数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;vq-的训练&#34;&gt;VQ 的训练&lt;/h2&gt;
&lt;p&gt;可以看出带有 VQ bottleneck 的优化并不容易。原因在于将 $z$ 转化为 $z_q$ 时存在一个 $\arg\min$ 操作，它是不可导的。&lt;/p&gt;
&lt;p&gt;为了方便，我们把神经网络在 VQ bottleneck 前的部分看作 encoder，其作用是将输入 $x$ 转化成连续向量 $z$，把 VQ bottleneck 后的部分称为 decoder，其作用是从量化后的向量 $z_q$ 中解码出需要的输出。带有 VQ bottleneck的神经网络的参数分为三部分，即 encoder 的参数 $\theta_{\text{enc}}$，decoder 的参数 $\theta_{\text{dec}}$，以及词表 $e$。decoder 的参数的优化不存在任何问题，因为它是以 $z_q$ 作为输入的，$z_q$ 是怎么来的与它无关，只需要优化神经网络原来的 loss即可。而 encoder 的参数则问题很大，因为它以 $z$ 作为输出， decoder 的梯度回传只能到 $z_q$，而 $z$ 到 $z_q$ 是不存在梯度的。在VQVAE中提出了一个近似方法，即用 $z_q$ 的梯度作为 $z$ 的梯度。原因在于两者的维度都是 $D$，并且 $z_q$ 是 $z$ 的近似，因此它们的梯度应该是相似的。给定 decoder 的输出目标 $y$，假设原来的 loss 为 $l(y, \text{Dec}(z))$，则加上 VQ bottleneck 之后的 loss 为&lt;/p&gt;
&lt;p&gt;$$
l(y,\text{Dec}(z+sg(z_q-z)))
$$&lt;/p&gt;
&lt;p&gt;其中 $sg$ 表示 stop gradient，即在 backward 的时候不计算着一部分的梯度。在 PyTorch 中实现这个近似也比较容易，只要用 &lt;code&gt;z+(z_q-z).detach()&lt;/code&gt; 替代 &lt;code&gt;z_q&lt;/code&gt; 进行后续的 forward 计算即可。&lt;/p&gt;
&lt;p&gt;通过以上方法我们优化了 encoder 和 decoder 部分，但是还没有优化 VQ 过程。VQ 过程的优化目标是使量化后的表示 $z_q$ 尽可能地接近 $z$。因此我们直接优化 $z_q$ 和 $z$ 的 mean-squared-error loss，即 $|z_q-z|_2^2$。这个 loss 可以进一步拆分为两部分，即 $|z_q-sg(z)|_2^2$ 和 $|z-sg(z_q)|_2^2$。前者使得 codebook 中离 $z$ 最近的向量进一步接近 $z$，后者使得 $z$ 进一步接近 codebook 中离它最近的向量。相对来说，我们更希望 codebook 中的向量去接近 $z$，因此前者的权重更大一些。&lt;/p&gt;
&lt;p&gt;最终我们优化的 loss 为
$$
l(y, \text{Dec}(z+sg(z_q-z)))+\alpha |z_q-sg(z)|_2^2+\beta |z-sg(z_q)|_2^2
$$&lt;/p&gt;
&lt;p&gt;在整个 loss 中，只有第二项的 loss 与 codebook 的更新有关，其实也可以直接得到一个 closed-form optimal。假设 ${z_{i,1},z_{i,2},\cdots,z_{i,n_i}}$ 为 encoder 输出中离散近似为 $e_i$ 的 $n_i$个向量，则根据 MSE loss 的性质 $e_i$ 最优解为
$$
e_i = \frac{1}{n_i}\sum_{j=1}^{n_i}z_{i,j}
$$&lt;/p&gt;
&lt;p&gt;不过实际中我们都是使用 minibatch 进行训练，在每一步优化时只能看到 batch 中的样本。因此我们使用 exponential moving average（EMA）来进行更新
$$
N_i^{(t)}=N_i^{(t-1)}&lt;em&gt;\gamma+n_i^{(t)}(1-\gamma)\
m_i^{(t)}=m_i^{(t-1)}&lt;/em&gt;\gamma+\sum_jz_{i,j}^{(t)}(1-\gamma)
$$&lt;/p&gt;
&lt;p&gt;使用EMA更新 codebook 时，loss可以改为
$$
l(y, \text{Dec}(z+sg(z_q-z))+\beta |z-sg(z_q)|_2^2
$$&lt;/p&gt;
&lt;h2 id=&#34;vq-的训练心得&#34;&gt;VQ 的训练心得&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;codebook 的初始化非常重要&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;无论是否使用 EMA，codebook 中都只有被激活的向量才会被更新。因此如果 codebook 中某些向量从一开始就没有激活，那么这些向量就一直不会被更新，导致使用的 codebook 大小过小。之前很多研究表明预训练模型中连续向量的分布并不是在整个欧几里得空间上均匀的，而是集中分布在一个较小的区域。因此完全随机初始化的 codebook 往往只有一小部分向量会被激活。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;超参数选择的意义&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用 EMA 更新的方法相当于直接计算了 codebook 最优解，收敛速度会更快。$\gamma$ 决定了 codebook 更新的速率，$\gamma$ 越小 codebook 更新越快。&lt;/p&gt;
&lt;p&gt;系数为 $\beta$ 的 loss 项其实是对 $z$ 的一个正则项。$z$ 的复杂度是由 encoder 的参数量决定的，而 $z_q$ 的复杂度是由 codebook 的大小决定的，实际中 $z$ 的复杂度一般远大于 $z_q$。如果不加约束的话 $z_q$ 永远也追不上 $z$。而用 $z_q$ 的梯度近似 $z$ 的梯度要求 $z$ 和 $z_q$ 必须非常接近。因此需要用 $\beta$ 来约束 $z$ 的复杂度。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;如何防止 codebook collapse&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在学习过程中 $z$ 的分布是始终在变化中的，即使初始化的时候 codebook 中的大部分向量都能被激活，随着训练的进行，codebook 中被激活的向量也可能会越来越少。这个现象被称为 codebook collapse。通过仔细设置 $\gamma$, $\beta$ 和 学习率可以缓解这一问题，但是会非常麻烦。&lt;/p&gt;
&lt;p&gt;另一个想法是，我们可以重新初始化 codebook 中长时间没有被激活的向量，这个想法我是在 &lt;a href=&#34;http://arxiv.org/abs/2005.00341&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jukebox: A Generative Model for Music&lt;/a&gt; 中看到的。使用 EMA 更新的时候 $N_i^{(t)}$ 实际上已经记录了向量 $e_i$ 在过去被激活次数的 exponential moving average，可以用来判断有哪些向量长期没有被激活。至于如何重新初始化这些向量，我们希望重新初始化之后这些向量能够被激活，因此我们可以用当前 batch 中的 $z$ 来重新初始化这些向量。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>关于 MHLA（Multi-Head Latent Attention）的一些分析</title>
      <link>https://zxdu.xyz/post/mhla/</link>
      <pubDate>Thu, 09 May 2024 21:26:09 +0800</pubDate>
      <guid>https://zxdu.xyz/post/mhla/</guid>
      <description>&lt;p&gt;原始的 Multi-Head Attention 的计算公式为（单个head，暂时先不考虑 RoPE）&lt;/p&gt;
&lt;p&gt;$$
Q_i=W^Q_iH
$$&lt;/p&gt;
&lt;p&gt;$$
K_i=W_i^KH
$$
$$
V_i=W^V_iH
$$
$$
O_i=\text{Softmax}(\frac{Q_i^TK_i}{\sqrt{d_h}})V_i
$$
其中$H$ 是 $d\times l$ 的矩阵（$l$ 为序列长度），表示 hidden states， $W^Q_i, W^K_i, W^V_i$ 是 $d_h\times d$的矩阵。&lt;/p&gt;
&lt;p&gt;Multi-Query Attention 的计算公式为（单个head，暂时先不考虑 RoPE）
$$
Q_i=W^Q_iH
$$&lt;/p&gt;
&lt;p&gt;$$
K=W^KH
$$
$$
V=W^VH
$$
$$
O_i=Softmax(\frac{Q_i^TK}{\sqrt{d_h}})V_i
$$
最大的区别在于 $K,V$ 是所有 head共享的，因此能够减少KV Cache的显存占用。其中
$$
Q_i^TK=H^T(W_i^Q)^TW^KH
$$
Multi-Head Latent Attention 的计算公式为（单个head，暂时先不考虑 RoPE）
$$
C^Q=W^{DQ}H
$$
$$
Q_i=W^{UQ}_iC^Q
$$
$$
C^{KV}=W^{DKV}H
$$
$$
K_i=W_i^{UK}C^{KV}
$$
$$
V_i=W_i^{UV}C^{KV}
$$
$$
O_i=Softmax(\frac{Q_i^TK_i}{\sqrt{d_h}})V_i
$$
其中 $W^{DQ}, W^{DKV}\in \mathbb{R}^{d_c\times d}$，$W_i^{UQ},W_i^{UK},W_i^{UV}\in\mathbb{R}^{d_h\times d_c}$&lt;/p&gt;
&lt;p&gt;单独看 Attention 计算的前一部分，其中
$$
Q_i^TK_i=H^T(W^{DQ})^T(W_i^{UQ})^TW^{UK}_iW^{DKV}H
$$
令 $W_i^Q=(W_i^{UK})^TW_i^{UQ}W^{DQ}$，我们有
$$
Q_i^TK_i=H^T(W_i^Q)^TW^{DKV}H
$$
可以看到这一计算公式和 Multi-Query Attention 其实是一样的，都是使用的单独的 $Q$ 和共享的 $K$。区别在于，这里 $W_i^QH,W^{DKV}H\in\mathbb{R}^{d_c\times l}$。也就是说在进行 attention 计算的时候，向量点积的维度是 $d_c$  而不是 $d$。在论文中实际设置的是 $d_c=4d$。&lt;strong&gt;也就是说 Multi-Head Latent Attention 其实是 head dimension 提高到4倍的 Multi-Query Attention&lt;/strong&gt;。在论文中也提到了在 inference 的时候 absorb $W^{UK}$ into $W^{UQ}$，其实就代表了这里的结合方式。因为每个head的维度提高了，所以能够计算出更加复杂的 attention分布，从而相比起 Multi-Query Attention 取得性能提升。相比起直接提高 head dimension，其优点在于所有head的 $W^{DQ},W^{UQ},W^{UK}$的总参数量是 $d\cdot d_c+d \cdot d_c+ d \cdot d_c=3d\cdot d_c=12d\cdot d_h$，而所有 head 的 $W^Q$ 的参数量是 $d \cdot d_c\cdot n_h=4d^2$，节省了参数量。也就是说对 $W^Q$ 做了一个低秩分解。&lt;/p&gt;
&lt;p&gt;但是这个提升并不是 free lunch，因为 head dimension 提高意味着 attention 的计算量也提高，而 attention 的计算量是 $O(l^2)$ 的。为了处理长文本，现在大家一般都倾向于尽可能降低 attention 计算量的常数，而这个方法是会增加常数的。&lt;/p&gt;
&lt;p&gt;以上分析没有考虑 RoPE，如果考虑 RoPE 的话，每个 head 的维度会从 $4d$ 变成 $4.5d$，其中$4d$是没有 positional encoding的，$0.5d$ 是使用 RoPE encoding的。其实 ChatGLM2-6B 中已经使用过类似的&lt;a href=&#34;https://huggingface.co/THUDM/chatglm2-6b/blob/main/modeling_chatglm.py#L161&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;做法&lt;/a&gt;，即只在一半的 head dimension 上使用 RoPE ，目的是为了把 attention 计算分成位置相关和位置无关的两部分，与性能提升的关系并不大。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>用Vaultwarden搭建自己的密码管理服务</title>
      <link>https://zxdu.xyz/post/bitwarden/</link>
      <pubDate>Sun, 10 Jul 2022 23:35:00 +0800</pubDate>
      <guid>https://zxdu.xyz/post/bitwarden/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;密码是我们在互联网上使用各种服务的时候很难绕过的一环。我们经常能听到各种各样的科普文章中告诫我们，为了保护好自己的互联网账号，密码一定要足够复杂，最好能把大小写字母、数字、特殊符号都用上。但是，复杂的密码意味着难以记忆，而当下一个普通的互联网用户很可能拥有几十个账户。为了不折磨自己的脑细胞，很多人选择给多个账户使用同一个密码。然而，由于有的网站在数据安全方面疏于防护，用户的密码遭到泄漏的事故时有发生。虽然这些密码遭到泄漏的账户可能没有很高的价值，但是却可能导致使用了同样密码的高价值账户被盗。此外，有的人还在创建复杂密码的时候还会使用自己的姓名缩写、生日、手机号等信息，这也为通过社会工程学手段破解密码提供了可能。&lt;/p&gt;
&lt;p&gt;为了解决这一问题，密码管理服务应运而生。密码管理服务为用户提供了存储互联网账户的用户名和密码的服务，往往还会和浏览器、手机操作系统等结合，提供自动填充、自动记录等功能。在安全性方面，无论是存储在本地还是云端，都会用用户设置的密码进行加密。有了密码管理服务，我们就可以给每个互联网账户使用随机生成的强密码。最常见的密码管理服务就是Chrome、Edge等浏览器自带的密码自动填充功能和iOS、MacOS提供的系统级密码管理。我之前使用的也是Chrome的自动填充功能，但是这个功能毕竟是绑定了Chrome浏览器和谷歌账号。这就限制了浏览器的选择，比如前段时间使用Chromium内核的Edge很火，但是因为自己的互联网账号密码都保存在Chrome上，所以无法尝试。类似的，苹果的密码管理服务也不方便在Windows和Android下使用。因此我最近决定迁移到相对独立的密码管理软件上。&lt;/p&gt;
&lt;h2 id=&#34;为什么选择bitwarden&#34;&gt;为什么选择BitWarden&lt;/h2&gt;
&lt;p&gt;密码管理服务的安全性来自于现代加密算法，在无法攻破加密密码的情况下是无法获得加密内容的。但是为了能够在不同的设备上使用保管的密码，我们必须依赖于云端服务。而一旦涉及到云服务，就存在着很大的不确定性，因为我们很难检查服务器上实际运行的代码。这也是我没有选择很热门的1Password的原因。&lt;/p&gt;
&lt;p&gt;BitWarden是前后端均开源的密码管理服务器，并且还支持由用户自己搭建后端服务。当然实际中大家使用更多的是&lt;a href=&#34;https://github.com/dani-garcia/vaultwarden&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vaultwarden&lt;/a&gt;（原名为BitWarden_RS）这个非官方简化版后端实现，因为它占用的资源更少。同时BitWarden的前端也有很好的跨平台支持，对主流的浏览器和操作系统都提供了支持。&lt;/p&gt;
&lt;h2 id=&#34;如何搭建自己的vaultwarden服务&#34;&gt;如何搭建自己的Vaultwarden服务&lt;/h2&gt;
&lt;p&gt;首先用docker容器运行Vaultwarden服务&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull vaultwarden/server:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir /vw-data &lt;span class=&#34;c1&#34;&gt;# this is used for permanent data storage&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -d --name vaultwarden &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; -e &lt;span class=&#34;nv&#34;&gt;WEBSOCKET_ENABLED&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; -v /vw-data/:/data/ &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; -p 10020:80 -p 3012:3012 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; vaultwarden/server:latest
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中10020和3012分别是主服务和WebSocket服务的端口，&lt;code&gt;/vw-data&lt;/code&gt;是用来保存数据的文件夹。&lt;/p&gt;
&lt;p&gt;然后在域名服务商的管理页面添加DNS记录，将准备的域名指向服务器的IP地址。作为例子，这里假设我们准备的域名是www.example.com，服务器的IP是1.1.1.1。&lt;/p&gt;
&lt;p&gt;然后安装certbot&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;apt-get install -y snapd
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;snap install core&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; sudo snap refresh core
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;snap install --classic certbot
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ln -s /snap/bin/certbot /usr/bin/certbo
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后使用certbot进行证书生成&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://github.com/joohoi/acme-dns-certbot-joohoi/raw/master/acme-dns-auth.py
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x acme-dns-auth.py &lt;span class=&#34;c1&#34;&gt;# 注意要更改acme-dns-auth.py的首行的python为python3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mv acme-dns-auth.py /etc/letsencrypt/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;certbot certonly --manual --manual-auth-hook /etc/letsencrypt/acme-dns-auth.py --preferred-challenges dns --debug-challenges -d &lt;span class=&#34;se&#34;&gt;\*&lt;/span&gt;.www.example.com -d www.example.com
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在最后一步会要求你在域名的DNS配置中添加一个CNAME项来认证你的所有权，完成之后等待DNS更新之后按下回车。如果还没有更新完成就回车的话认证会失败，可以重新运行这一命令。证书相关的文件保存在&lt;code&gt;/etc/letsencrypt/live/www.example.com&lt;/code&gt;下面。&lt;/p&gt;
&lt;p&gt;最后在&lt;code&gt;/etc/nginx/conf.d/vaultwarden.conf&lt;/code&gt;中进行nginx配置（需要先安装nginx）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# Redirect HTTP to HTTPS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;server {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    listen 80;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    listen [::]:80;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    server_name www.example.com;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    return 301 https://$host$request_uri;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;server {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  listen 443 ssl http2;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  listen [::]:443 ssl http2;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  server_name www.example.com;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ssl_certificate /etc/letsencrypt/live/www.example.com/fullchain.pem;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  ssl_certificate_key /etc/letsencrypt/live/www.example.com/privkey.pem;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  # Specify SSL config if using a shared one.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  #include conf.d/ssl/ssl.conf;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  # Allow large attachments
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  client_max_body_size 128M;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  location / {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_pass http://127.0.0.1:10020;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_set_header Host $host;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_set_header X-Real-IP $remote_addr;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_set_header X-Forwarded-Proto $scheme;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  location /notifications/hub {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_pass http://127.0.0.1:3012;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_set_header Upgrade $http_upgrade;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_set_header Connection &amp;#34;upgrade&amp;#34;;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  location /notifications/hub/negotiate {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    proxy_pass http://127.0.0.1:10020;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后就可以在www.example.com中访问自己的BitWarden服务了。在使用各个平台的BitWarden插件和客户端的时候，要在登陆之前先进行设置，将服务地址修改为www.example.com。&lt;/p&gt;
&lt;h2 id=&#34;更新vaultwarden镜像&#34;&gt;更新Vaultwarden镜像&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Pull the latest version&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull vaultwarden/server:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Stop and remove the old container&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker stop vaultwarden
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker rm vaultwarden
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Start new container with the data mounted&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -d --name vaultwarden &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; -e &lt;span class=&#34;nv&#34;&gt;WEBSOCKET_ENABLED&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; -v /vw-data/:/data/ &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; -p 10020:80 -p 3012:3012 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt; vaultwarden/server:latest
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Installing Vaultwarden formally bitwarden_rs on Ubuntu 20.04 with Nginx. &lt;a href=&#34;https://www.llewellynhughes.co.uk/post/installing-vaultwarden&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.llewellynhughes.co.uk/post/installing-vaultwarden&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vaultwarden Wiki. &lt;a href=&#34;https://github.com/dani-garcia/vaultwarden/wiki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/dani-garcia/vaultwarden/wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>
